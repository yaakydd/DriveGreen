{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ec56ea9",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92adac6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the libraries needed for EDA\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13d9af95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loaading the dataset\n",
    "emissions_data = pd.read_csv(\"Emissions_Canada.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efe40874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['make', 'model', 'vehicle_class', 'engine_size(l)', 'cylinders', 'transmission', 'fuel_type', 'fuel_consumption_city_(l/100_km)', 'fuel_consumption_hwy_(l/100_km)', 'fuel_consumption_comb_(l/100_km)', 'fuel_consumption_comb_(mpg)', 'co2_emissions(g/km)']\n"
     ]
    }
   ],
   "source": [
    "#Converting all columns names to lowercase\n",
    "emissions_data.columns = emissions_data.columns.str.lower()\n",
    "\n",
    "# Remove leading/trailing spaces and replace internal spaces with underscores\n",
    "emissions_data.columns = emissions_data.columns.str.strip().str.replace(' ', '_')\n",
    "\n",
    "print(emissions_data.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17fb058a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9\n",
      "8.4\n",
      "3\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "\n",
    "min_val = emissions_data['engine_size(l)'].min()\n",
    "max_val = emissions_data['engine_size(l)'].max()\n",
    "\n",
    "\n",
    "mine_val = emissions_data['cylinders'].min()\n",
    "maxe_val = emissions_data['cylinders'].max()\n",
    "\n",
    "print(min_val)\n",
    "print(max_val)\n",
    "print(mine_val)\n",
    "print(maxe_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22cd1847",
   "metadata": {},
   "outputs": [],
   "source": [
    "emissions_data.rename(columns={'co2_emissions(g/km)': 'co2_emissions'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26f73732",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting the feature columns and the target column\n",
    "target_variable = 'co2_emissions'\n",
    "numerical_features = ['engine_size(l)', 'cylinders']\n",
    "categorical_feature = 'fuel_type'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32e5ec6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transforming the data\n",
    "\n",
    "transformed_numerical_features = np.log(emissions_data[numerical_features])\n",
    "transformed_target_variable = np.log(emissions_data[target_variable])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd74430",
   "metadata": {},
   "source": [
    "### Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d8cf3a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yaa_baby/.local/lib/python3.8/site-packages/xgboost/core.py:265: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc 2.28+) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Import ML tools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Import models\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from xgboost import XGBRegressor\n",
    "import joblib, os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad1797b",
   "metadata": {},
   "source": [
    "The code below trains 4 different models and has an additional 2 models for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a1657c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression → MAE: 242971666.99, RMSE: 9337828230.43, R²: -1536157724923129495552.00\n",
      "KNN → MAE: 0.09, RMSE: 0.12, R²: 0.75\n",
      "Random Forest → MAE: 0.08, RMSE: 0.11, R²: 0.77\n",
      "SVM (RBF) → MAE: 0.09, RMSE: 0.12, R²: 0.73\n",
      "Gradient Boosting → MAE: 0.08, RMSE: 0.12, R²: 0.76\n",
      "XGBoost → MAE: 0.08, RMSE: 0.11, R²: 0.77\n",
      "Best model: XGBoost\n",
      "Model and encoder saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Combine transformed numerical features + categorical into one DataFrame that is X\n",
    "X = pd.concat([transformed_numerical_features, emissions_data[[categorical_feature]]], axis=1)\n",
    "y = transformed_target_variable.copy()\n",
    "\n",
    "\n",
    "# One-Hot Encode the categorical feature\n",
    "\n",
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "encoded_categorical_feature = encoder.fit_transform(X[[categorical_feature]])\n",
    "\n",
    "# Convert encoded columns into a DataFrame\n",
    "encoded_cat_df = pd.DataFrame(\n",
    "    encoded_categorical_feature,\n",
    "    columns=encoder.get_feature_names_out([categorical_feature]),\n",
    "    index=X.index\n",
    ")\n",
    "\n",
    "# Merge numerical and encoded categorical columns\n",
    "X_encoded = pd.concat([X.drop(columns=[categorical_feature]), encoded_cat_df], axis=1)\n",
    "\n",
    "\n",
    "#Spliting the data into training and testing\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Scale Numerical Features\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "# Define Models\n",
    "\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'KNN': KNeighborsRegressor(n_neighbors=5),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    'SVM (RBF)': SVR(kernel='rbf'),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, random_state=42),\n",
    "    'XGBoost': XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "}\n",
    "\n",
    "# Train and evaluate models\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    predicted_y = model.predict(X_test_scaled)\n",
    "\n",
    "    mae = mean_absolute_error(y_test, predicted_y)\n",
    "    rmse = mean_squared_error(y_test, predicted_y, squared=False)\n",
    "    r2 = r2_score(y_test, predicted_y)\n",
    "\n",
    "    results[name] = {'MAE': mae, 'RMSE': rmse, 'R2': r2}\n",
    "    print(f\"{name} → MAE: {mae:.2f}, RMSE: {rmse:.2f}, R²: {r2:.2f}\")\n",
    "\n",
    "# Convert results dictionary to a DataFrame\n",
    "results_df = pd.DataFrame(results).T.reset_index().rename(columns={'index': 'Model'})\n",
    "\n",
    "# Create folder to save models\n",
    "os.makedirs(\"model\", exist_ok=True)\n",
    "\n",
    "# Select best model based on highest R²\n",
    "best_model_name = results_df.loc[results_df['R2'].idxmax(), 'Model']\n",
    "print(\"Best model:\", best_model_name)\n",
    "\n",
    "# Retrieve best model object from the dictionary\n",
    "best_model = models[best_model_name]\n",
    "\n",
    "# Save model + encoder + scaler\n",
    "joblib.dump(best_model, f\"model/{best_model_name.replace(' ', '_').lower()}_model.pkl\")\n",
    "joblib.dump(encoder, \"model/encoder.pkl\")\n",
    "joblib.dump(scaler, \"model/scaler.pkl\")\n",
    "\n",
    "print(\" Model, encoder, and scaler saved successfully!\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
